#!/usr/bin/env python3
"""
ë™ì  ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬ - YouTube ì¸ê¸° ë™ì˜ìƒ
Seleniumì„ ì‚¬ìš©í•˜ì—¬ JavaScriptë¡œ ë Œë”ë§ë˜ëŠ” ì½˜í…ì¸ ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import pandas as pd
import json
import time
from datetime import datetime
import re


class YouTubeTrendingCrawler:
    def __init__(self, headless=True):
        """
        YouTube íŠ¸ë Œë”© í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            headless: ë¸Œë¼ìš°ì €ë¥¼ í™”ë©´ì— í‘œì‹œí•˜ì§€ ì•Šì„ì§€ ì—¬ë¶€
        """
        self.videos = []
        self.driver = None
        self.headless = headless
        
    def setup_driver(self):
        """Selenium WebDriver ì„¤ì •"""
        print("Chrome WebDriver ì„¤ì • ì¤‘...")
        
        # Chrome ì˜µì…˜ ì„¤ì •
        chrome_options = Options()
        
        if self.headless:
            chrome_options.add_argument("--headless")  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
        
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36")
        
        # ë¶ˆí•„ìš”í•œ ë¡œê·¸ ì œê±°
        chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
        chrome_options.add_argument("--log-level=3")
        
        try:
            self.driver = webdriver.Chrome(options=chrome_options)
            print("âœ“ WebDriver ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            print(f"WebDriver ì„¤ì • ì‹¤íŒ¨: {e}")
            print("Chrome ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return False
        
        return True
    
    def parse_view_count(self, view_text):
        """ì¡°íšŒìˆ˜ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜"""
        if not view_text:
            return 0
        
        # "ì¡°íšŒìˆ˜ 1.2ë§ŒíšŒ" -> 12000
        # "ì¡°íšŒìˆ˜ 523ë§ŒíšŒ" -> 5230000
        # "ì¡°íšŒìˆ˜ 1.5ì²œíšŒ" -> 1500
        
        view_text = view_text.replace("ì¡°íšŒìˆ˜", "").replace("íšŒ", "").strip()
        
        if "ë§Œ" in view_text:
            number = float(view_text.replace("ë§Œ", "").replace(",", ""))
            return int(number * 10000)
        elif "ì²œ" in view_text:
            number = float(view_text.replace("ì²œ", "").replace(",", ""))
            return int(number * 1000)
        elif "ì–µ" in view_text:
            number = float(view_text.replace("ì–µ", "").replace(",", ""))
            return int(number * 100000000)
        else:
            try:
                return int(view_text.replace(",", ""))
            except:
                return 0
    
    def scroll_page(self, scroll_count=3):
        """í˜ì´ì§€ ìŠ¤í¬ë¡¤í•˜ì—¬ ë” ë§ì€ ì½˜í…ì¸  ë¡œë“œ"""
        print(f"í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘... (ì´ {scroll_count}íšŒ)")
        
        for i in range(scroll_count):
            # í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
            self.driver.execute_script("window.scrollTo(0, document.documentElement.scrollHeight);")
            time.sleep(2)  # ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸°
            print(f"  ìŠ¤í¬ë¡¤ {i+1}/{scroll_count} ì™„ë£Œ")
    
    def crawl_youtube_trending(self):
        """YouTube ì¸ê¸° ë™ì˜ìƒ í¬ë¡¤ë§"""
        url = "https://www.youtube.com/feed/trending"
        
        print(f"\ní¬ë¡¤ë§ ì‹œì‘: {url}")
        self.driver.get(url)
        
        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        try:
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "ytd-video-renderer"))
            )
            print("âœ“ í˜ì´ì§€ ë¡œë”© ì™„ë£Œ")
        except TimeoutException:
            print("âŒ í˜ì´ì§€ ë¡œë”© íƒ€ì„ì•„ì›ƒ")
            return False
        
        # ìŠ¤í¬ë¡¤í•˜ì—¬ ë” ë§ì€ ë™ì˜ìƒ ë¡œë“œ
        self.scroll_page(scroll_count=3)
        
        # ë™ì˜ìƒ ì •ë³´ ì¶”ì¶œ
        video_elements = self.driver.find_elements(By.TAG_NAME, "ytd-video-renderer")
        print(f"\nì´ {len(video_elements)}ê°œì˜ ë™ì˜ìƒ ë°œê²¬")
        
        for idx, video in enumerate(video_elements, 1):
            try:
                # ì œëª©
                title_element = video.find_element(By.ID, "video-title")
                title = title_element.text
                video_url = title_element.get_attribute("href")
                
                # ì±„ë„ëª…
                try:
                    channel = video.find_element(By.CSS_SELECTOR, "#channel-name #text").text
                except:
                    channel = "Unknown"
                
                # ì¡°íšŒìˆ˜ ë° ì—…ë¡œë“œ ì‹œê°„
                metadata_elements = video.find_elements(By.CSS_SELECTOR, "#metadata-line span")
                views = ""
                upload_time = ""
                
                if len(metadata_elements) >= 2:
                    views = metadata_elements[0].text
                    upload_time = metadata_elements[1].text
                
                # ì¸ë„¤ì¼
                try:
                    thumbnail = video.find_element(By.CSS_SELECTOR, "img#img").get_attribute("src")
                except:
                    thumbnail = ""
                
                # ë™ì˜ìƒ ê¸¸ì´
                try:
                    duration = video.find_element(By.CSS_SELECTOR, "span#text.ytd-thumbnail-overlay-time-status-renderer").text
                except:
                    duration = ""
                
                # ì¡°íšŒìˆ˜ íŒŒì‹±
                view_count = self.parse_view_count(views)
                
                self.videos.append({
                    'rank': idx,
                    'title': title,
                    'channel': channel,
                    'views': views,
                    'view_count': view_count,
                    'upload_time': upload_time,
                    'duration': duration,
                    'url': video_url,
                    'thumbnail': thumbnail,
                    'crawled_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })
                
                print(f"  [{idx}] {title[:50]}... - {channel}")
                
            except Exception as e:
                print(f"  âŒ ë™ì˜ìƒ {idx} íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
        
        return True
    
    def crawl_google_search(self, query="Python programming"):
        """Google ê²€ìƒ‰ ê²°ê³¼ í¬ë¡¤ë§ (ë™ì  ë¡œë”© ì˜ˆì œ)"""
        url = f"https://www.google.com/search?q={query}"
        
        print(f"\nğŸ” Google ê²€ìƒ‰ í¬ë¡¤ë§: '{query}'")
        self.driver.get(url)
        
        # ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
        try:
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div.g"))
            )
        except TimeoutException:
            print("ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ì‹¤íŒ¨")
            return []
        
        search_results = []
        result_elements = self.driver.find_elements(By.CSS_SELECTOR, "div.g")[:10]
        
        for idx, result in enumerate(result_elements, 1):
            try:
                # ì œëª©ê³¼ ë§í¬
                title_elem = result.find_element(By.CSS_SELECTOR, "h3")
                title = title_elem.text
                
                link_elem = result.find_element(By.CSS_SELECTOR, "a")
                link = link_elem.get_attribute("href")
                
                # ì„¤ëª…
                try:
                    desc_elem = result.find_element(By.CSS_SELECTOR, "span.aCOpRe, div.VwiC3b")
                    description = desc_elem.text
                except:
                    description = ""
                
                search_results.append({
                    'rank': idx,
                    'title': title,
                    'link': link,
                    'description': description[:200]
                })
                
                print(f"  [{idx}] {title[:50]}...")
                
            except Exception as e:
                continue
        
        return search_results
    
    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        if not self.videos:
            print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # CSV ì €ì¥
        df = pd.DataFrame(self.videos)
        df.to_csv('youtube_trending.csv', index=False, encoding='utf-8-sig')
        print(f"âœ“ CSV íŒŒì¼ ì €ì¥: youtube_trending.csv")
        
        # JSON ì €ì¥
        with open('youtube_trending.json', 'w', encoding='utf-8') as f:
            json.dump(self.videos, f, ensure_ascii=False, indent=2)
        print(f"âœ“ JSON íŒŒì¼ ì €ì¥: youtube_trending.json")
        
        # ìƒìœ„ 10ê°œ ì¶œë ¥
        print("\n" + "="*80)
        print("YouTube ì¸ê¸° ë™ì˜ìƒ TOP 10")
        print("="*80)
        
        for video in self.videos[:10]:
            print(f"\n[{video['rank']}ìœ„] {video['title']}")
            print(f"    ì±„ë„: {video['channel']}")
            print(f"    ì¡°íšŒìˆ˜: {video['views']} ({video['view_count']:,})")
            print(f"    ì—…ë¡œë“œ: {video['upload_time']}")
            print(f"    ê¸¸ì´: {video['duration']}")
            print(f"    URL: {video['url']}")
    
    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            print("âœ“ WebDriver ì¢…ë£Œ")
    
    def run(self):
        """í¬ë¡¤ë§ ì‹¤í–‰"""
        try:
            # ë“œë¼ì´ë²„ ì„¤ì •
            if not self.setup_driver():
                return
            
            # YouTube í¬ë¡¤ë§
            if self.crawl_youtube_trending():
                self.save_results()
            
            # Google ê²€ìƒ‰ ì˜ˆì œ (ì„ íƒì )
            # search_results = self.crawl_google_search("Python web scraping")
            # print(f"\nGoogle ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ")
            
        except Exception as e:
            print(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            self.close()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*80)
    print("ë™ì  ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬ - YouTube ì¸ê¸° ë™ì˜ìƒ")
    print("="*80)
    
    # headless=Falseë¡œ ì„¤ì •í•˜ë©´ ë¸Œë¼ìš°ì €ê°€ ì‹¤ì œë¡œ ì—´ë¦¼
    crawler = YouTubeTrendingCrawler(headless=True)
    crawler.run()
    
    print("\nâœ… í¬ë¡¤ë§ ì™„ë£Œ!")


if __name__ == "__main__":
    main()